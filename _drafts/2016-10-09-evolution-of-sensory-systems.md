---
layout: post
title: "Sensory systems as general-purpose representations"
description: ""
categories: articles
tags: neuro
---

About the brain being a deep learning (sensory system) + reinforcement learning (basal ganglia) machine. And my question, which I'd brought up last night as a sort of mystery, of how it is that the brain could evolve a general problem-solving system (i.e., a sensory system) given that initially it must have had to solve only a handful of really important issues (e.g., how to access water, food, air, shelter, etc.). In other words, how is it that solving two of these problems--say, finding water and finding shelter--could both be solved by a system we now call "the visual system." But Jess and I sorted it out...It actually involved another part of the CNBC retreat, which was the "sensory substitution" talk and the quote mentioned there that said "We don't see with our eyes, we see with our brain." Jess's reply was "Oh, that's completely wrong," because vision is about processing light. So the point here is that light exists, and any organism that realizes that processing light could help solve both finding water and finding shelter would be better off, because it would take less energy than using two different processes for finding these. And the "we don't see with our eyes" quote could be rephrased as saying "We don't see with light, we see with our brain," which is clearly absurd. Seeing is about processing light information. Really all the quote is saying is "We can process the world in ways other than vision, but we can use the visual system to do this processing using the visual system if it's not busy," which sounds much less interesting. Like, it's not like if we amputate a finger and the somatosensory area that formerly processed that finger and now processes the remaining nearby fingers has anything to do with the finger that is now missing!

So how could an AI learn to play chess as an expert, and then use that same algorithm/approach to learn how to play other games? Or how to be a polite member of society? The answer will require finding representations of the world that are useful in a variety of settings. E.g., given evidence of its usefulness in biological species, the A.I. will need to discover "vision," because light information is a very general-purpose representation.

Also, if what deep learning does is convert a representation question (i.e., feature engineering) into an architecture question, isn't this the same as turning a computational perspective (a la Marr's levels of analysis) into an implementation/algorithmic perspective? Since it's now about what's wired to what.


